{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1720232461098
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\ch06\n",
            "c:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\n",
            "train loss:2.300239877214589\n",
            "=== epoch:1, train acc:0.196, test acc:0.219 ===\n",
            "train loss:2.297913982369684\n",
            "train loss:2.2936861863000213\n",
            "train loss:2.283828114866765\n",
            "train loss:2.280428020891306\n",
            "train loss:2.2563863360393728\n",
            "train loss:2.240312687040542\n",
            "train loss:2.231722166338058\n",
            "train loss:2.228734613160547\n",
            "train loss:2.1776328234537763\n",
            "train loss:2.191630433831012\n",
            "train loss:2.175906949215205\n",
            "train loss:2.1006670382786963\n",
            "train loss:2.0552650140463395\n",
            "train loss:1.961172296097409\n",
            "train loss:1.9420604977710545\n",
            "train loss:1.8788595838078412\n",
            "train loss:1.8135211523702535\n",
            "train loss:1.748070046068228\n",
            "train loss:1.7110169300990623\n",
            "train loss:1.605931904520284\n",
            "train loss:1.64672841881163\n",
            "train loss:1.5479483278344686\n",
            "train loss:1.3591800704709065\n",
            "train loss:1.3238500546454888\n",
            "train loss:1.2315543908922308\n",
            "train loss:1.1605081085777462\n",
            "train loss:1.1296139195329373\n",
            "train loss:0.9814495633760898\n",
            "train loss:1.0644214560672673\n",
            "train loss:0.9768453439918491\n",
            "train loss:0.9352178614723634\n",
            "train loss:0.8415301304446907\n",
            "train loss:0.6802512448508548\n",
            "train loss:0.7751574558329289\n",
            "train loss:0.8468602097856387\n",
            "train loss:0.8355107982926682\n",
            "train loss:0.6244762324196718\n",
            "train loss:0.6959068964271614\n",
            "train loss:0.7544234725618983\n",
            "train loss:0.7100375976072449\n",
            "train loss:0.6532952809605612\n",
            "train loss:0.8090268588913243\n",
            "train loss:0.516766282196434\n",
            "train loss:0.6320137109522384\n",
            "train loss:0.49785057362615975\n",
            "train loss:0.5061749963044524\n",
            "train loss:0.8111015164425963\n",
            "train loss:0.43982660606983726\n",
            "train loss:0.6442690760615787\n",
            "train loss:0.310806222540324\n",
            "=== epoch:2, train acc:0.801, test acc:0.799 ===\n",
            "train loss:0.8042907500586749\n",
            "train loss:0.6930520498018375\n",
            "train loss:0.5543777489496553\n",
            "train loss:0.4970416036085655\n",
            "train loss:0.6283356137337711\n",
            "train loss:0.39257356186306724\n",
            "train loss:0.5692805613976412\n",
            "train loss:0.5245053480854629\n",
            "train loss:0.5305672946723882\n",
            "train loss:0.5592563568012218\n",
            "train loss:0.4864768910529635\n",
            "train loss:0.3113003732482595\n",
            "train loss:0.5026747590242738\n",
            "train loss:0.39655077145418494\n",
            "train loss:0.43879681848597296\n",
            "train loss:0.3873978141733187\n",
            "train loss:0.4008488321539815\n",
            "train loss:0.4659670960745808\n",
            "train loss:0.4173443667244616\n",
            "train loss:0.44400052805385465\n",
            "train loss:0.5146874284812688\n",
            "train loss:0.46669865787837894\n",
            "train loss:0.29226074880847136\n",
            "train loss:0.34311000648463497\n",
            "train loss:0.3858433934111386\n",
            "train loss:0.43628994116325687\n",
            "train loss:0.35928228232922454\n",
            "train loss:0.3902251898278659\n",
            "train loss:0.5279382893531089\n",
            "train loss:0.4815069360512166\n",
            "train loss:0.3887065147521031\n",
            "train loss:0.4205490401436113\n",
            "train loss:0.340217487406055\n",
            "train loss:0.2774986213698639\n",
            "train loss:0.42827518252047286\n",
            "train loss:0.2683845081287601\n",
            "train loss:0.3414381029367846\n",
            "train loss:0.18727019546644766\n",
            "train loss:0.4268438691937895\n",
            "train loss:0.32191778334703314\n",
            "train loss:0.387204926897658\n",
            "train loss:0.3547991688181601\n",
            "train loss:0.5481796822122025\n",
            "train loss:0.2906118262162668\n",
            "train loss:0.19943352717804685\n",
            "train loss:0.544352526273832\n",
            "train loss:0.24277127083822697\n",
            "train loss:0.35185772716403235\n",
            "train loss:0.3691957783981972\n",
            "train loss:0.20199601370975942\n",
            "=== epoch:3, train acc:0.875, test acc:0.866 ===\n",
            "train loss:0.21699521952237294\n",
            "train loss:0.20881881061222082\n",
            "train loss:0.38472926166983146\n",
            "train loss:0.35193691387666803\n",
            "train loss:0.24196676088498217\n",
            "train loss:0.7192160329380874\n",
            "train loss:0.5575690769369902\n",
            "train loss:0.3635682148107675\n",
            "train loss:0.3775265260457134\n",
            "train loss:0.3035844388150385\n",
            "train loss:0.32630060809494876\n",
            "train loss:0.34236581362522694\n",
            "train loss:0.3879795476288881\n",
            "train loss:0.30204665475750575\n",
            "train loss:0.33314853319141313\n",
            "train loss:0.4338046551375423\n",
            "train loss:0.3251315131877486\n",
            "train loss:0.38579944472311994\n",
            "train loss:0.4852462543149715\n",
            "train loss:0.39418988135325106\n",
            "train loss:0.3323120577773405\n",
            "train loss:0.3331247811966198\n",
            "train loss:0.3754633418028708\n",
            "train loss:0.33457486792400376\n",
            "train loss:0.21954626711291525\n",
            "train loss:0.3632891413894759\n",
            "train loss:0.3075350487472772\n",
            "train loss:0.20087157981565906\n",
            "train loss:0.22836521342648655\n",
            "train loss:0.29757114724783346\n",
            "train loss:0.31420017662248356\n",
            "train loss:0.1551367791826477\n",
            "train loss:0.3423472148713995\n",
            "train loss:0.29772271742432344\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "print(os.getcwd())\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from ch06.simple_convnet import SimpleConvNet\n",
        "from common.trainer import Trainer\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
        "x_train, t_train = x_train[:5000], t_train[:5000]\n",
        "x_test, t_test = x_test[:1000], t_test[:1000]\n",
        "\n",
        "max_epochs = 20\n",
        "\n",
        "network = SimpleConvNet(input_dim=(1,28,28),\n",
        "                        conv_param={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
        "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
        "\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=max_epochs, mini_batch_size=100,\n",
        "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
        "                  evaluate_sample_num_per_epoch=1000)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# 매개변수 저장\n",
        "network.save_params(\"params.pkl\")\n",
        "print(\"네트워크 매개변수 저장 완료!\")\n",
        "import os, sys\n",
        "print(os.getcwd())  # 현재 작업 디렉토리 출력\n",
        "current_dir = os.path.dirname(os.getcwd())  # 현재 작업 디렉토리의 부모 디렉토리 경로 설정\n",
        "print(current_dir)  # 부모 디렉토리 경로 출력\n",
        "os.chdir(current_dir)  # 부모 디렉토리로 작업 디렉토리 변경\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist  # MNIST 데이터셋을 불러오는 함수\n",
        "from ch06.simple_convnet import SimpleConvNet  # 미리 정의한 간단한 CNN (SimpleConvNet 클래스)\n",
        "from common.trainer import Trainer  # 학습을 관리하는 Trainer 클래스\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)  # MNIST 데이터셋을 불러오고, 이미지 형태를 유지\n",
        "\n",
        "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
        "x_train, t_train = x_train[:5000], t_train[:5000]  # 훈련 데이터의 일부 5000개만 사용\n",
        "x_test, t_test = x_test[:1000], t_test[:1000]  # 테스트 데이터의 일부 1000개만 사용\n",
        "\n",
        "max_epochs = 20  # 학습을 반복할 최대 에포크 수 설정\n",
        "\n",
        "# CNN 신경망 설정\n",
        "network = SimpleConvNet(input_dim=(1, 28, 28),  # 입력 데이터의 차원 (흑백 1채널, 28x28 크기 이미지)\n",
        "                        conv_param={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},  # 합성곱 계층 설정 (필터 30개, 필터 크기 5x5)\n",
        "                        hidden_size=100,  # 은닉층의 뉴런 수\n",
        "                        output_size=10,  # 출력층의 크기 (10개의 숫자 분류)\n",
        "                        weight_init_std=0.01)  # 가중치 초기화 표준편차 설정\n",
        "\n",
        "# Trainer 설정 (훈련과정을 관리)\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,  # 신경망과 학습 데이터 설정\n",
        "                  epochs=max_epochs,  # 최대 에포크 수 설정\n",
        "                  mini_batch_size=100,  # 미니 배치 크기 설정 (한 번에 처리할 데이터 개수)\n",
        "                  optimizer='Adam',  # Adam Optimizer 사용\n",
        "                  optimizer_param={'lr': 0.001},  # Adam의 학습률 설정\n",
        "                  evaluate_sample_num_per_epoch=1000)  # 매 에포크마다 평가할 샘플 개수 설정\n",
        "\n",
        "trainer.train()  # 학습 시작\n",
        "\n",
        "# 매개변수 저장\n",
        "network.save_params(\"params.pkl\")  # 학습된 네트워크 매개변수를 \"params.pkl\" 파일로 저장\n",
        "print(\"네트워크 매개변수 저장 완료!\")  # 저장 완료 메시지 출력\n",
        "\n",
        "# 그래프 그리기\n",
        "markers = {'train': 'o', 'test': 's'}  # 훈련 데이터와 테스트 데이터의 마커 설정\n",
        "x = np.arange(max_epochs)  # x축은 에포크 수만큼 설정\n",
        "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)  # 훈련 정확도를 그래프로 그림\n",
        "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)  # 테스트 정확도를 그래프로 그림\n",
        "plt.xlabel(\"epochs\")  # x축 라벨 설정\n",
        "plt.ylabel(\"accuracy\")  # y축 라벨 설정\n",
        "plt.ylim(0, 1.0)  # y축 범위는 0~1.0 (정확도)\n",
        "plt.legend(loc='lower right')  # 범례 위치를 오른쪽 하단으로 설정\n",
        "plt.show()  # 그래프 출력\n",
        "\n",
        "# 그래프 그리기\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
        "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
