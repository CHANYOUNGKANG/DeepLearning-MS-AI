{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1729754484024
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\ch05\n",
            "C:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\n",
            "epoch:0, train acc:0.10333333333333333, test acc:0.0995\n",
            "epoch:1, train acc:0.12333333333333334, test acc:0.101\n",
            "epoch:2, train acc:0.14333333333333334, test acc:0.1116\n",
            "epoch:3, train acc:0.15333333333333332, test acc:0.1172\n",
            "epoch:4, train acc:0.18666666666666668, test acc:0.1295\n",
            "epoch:5, train acc:0.19666666666666666, test acc:0.1382\n",
            "epoch:6, train acc:0.20666666666666667, test acc:0.1509\n",
            "epoch:7, train acc:0.2, test acc:0.1574\n",
            "epoch:8, train acc:0.20666666666666667, test acc:0.1647\n",
            "epoch:9, train acc:0.22666666666666666, test acc:0.1788\n",
            "epoch:10, train acc:0.22666666666666666, test acc:0.1859\n",
            "epoch:11, train acc:0.24666666666666667, test acc:0.1964\n",
            "epoch:12, train acc:0.2733333333333333, test acc:0.2048\n",
            "epoch:13, train acc:0.28, test acc:0.21\n",
            "epoch:14, train acc:0.31666666666666665, test acc:0.2245\n",
            "epoch:15, train acc:0.35, test acc:0.2332\n",
            "epoch:16, train acc:0.39666666666666667, test acc:0.2456\n",
            "epoch:17, train acc:0.41, test acc:0.2575\n",
            "epoch:18, train acc:0.4066666666666667, test acc:0.2649\n",
            "epoch:19, train acc:0.42333333333333334, test acc:0.277\n",
            "epoch:20, train acc:0.4166666666666667, test acc:0.2835\n",
            "epoch:21, train acc:0.42, test acc:0.2895\n",
            "epoch:22, train acc:0.43333333333333335, test acc:0.2994\n",
            "epoch:23, train acc:0.45666666666666667, test acc:0.3107\n",
            "epoch:24, train acc:0.48333333333333334, test acc:0.3271\n",
            "epoch:25, train acc:0.49, test acc:0.3337\n",
            "epoch:26, train acc:0.5066666666666667, test acc:0.3472\n",
            "epoch:27, train acc:0.5066666666666667, test acc:0.3412\n",
            "epoch:28, train acc:0.49666666666666665, test acc:0.3409\n",
            "epoch:29, train acc:0.5333333333333333, test acc:0.3663\n",
            "epoch:30, train acc:0.5566666666666666, test acc:0.3797\n",
            "epoch:31, train acc:0.56, test acc:0.3995\n",
            "epoch:32, train acc:0.56, test acc:0.404\n",
            "epoch:33, train acc:0.57, test acc:0.4166\n",
            "epoch:34, train acc:0.5733333333333334, test acc:0.424\n",
            "epoch:35, train acc:0.5766666666666667, test acc:0.4376\n",
            "epoch:36, train acc:0.59, test acc:0.4406\n",
            "epoch:37, train acc:0.5933333333333334, test acc:0.4508\n",
            "epoch:38, train acc:0.6266666666666667, test acc:0.4766\n",
            "epoch:39, train acc:0.63, test acc:0.4874\n",
            "epoch:40, train acc:0.64, test acc:0.4883\n",
            "epoch:41, train acc:0.65, test acc:0.5004\n",
            "epoch:42, train acc:0.6533333333333333, test acc:0.5096\n",
            "epoch:43, train acc:0.67, test acc:0.5198\n",
            "epoch:44, train acc:0.6833333333333333, test acc:0.5307\n",
            "epoch:45, train acc:0.68, test acc:0.5293\n",
            "epoch:46, train acc:0.7033333333333334, test acc:0.5437\n",
            "epoch:47, train acc:0.71, test acc:0.5596\n",
            "epoch:48, train acc:0.7066666666666667, test acc:0.5566\n",
            "epoch:49, train acc:0.7, test acc:0.5603\n",
            "epoch:50, train acc:0.72, test acc:0.5649\n",
            "epoch:51, train acc:0.7333333333333333, test acc:0.5738\n",
            "epoch:52, train acc:0.73, test acc:0.5814\n",
            "epoch:53, train acc:0.75, test acc:0.5946\n",
            "epoch:54, train acc:0.7533333333333333, test acc:0.6045\n",
            "epoch:55, train acc:0.7666666666666667, test acc:0.6116\n",
            "epoch:56, train acc:0.7833333333333333, test acc:0.6138\n",
            "epoch:57, train acc:0.7733333333333333, test acc:0.6139\n",
            "epoch:58, train acc:0.79, test acc:0.6179\n",
            "epoch:59, train acc:0.7866666666666666, test acc:0.6208\n",
            "epoch:60, train acc:0.8033333333333333, test acc:0.6212\n",
            "epoch:61, train acc:0.79, test acc:0.618\n",
            "epoch:62, train acc:0.7833333333333333, test acc:0.6213\n",
            "epoch:63, train acc:0.7833333333333333, test acc:0.6228\n",
            "epoch:64, train acc:0.7833333333333333, test acc:0.6295\n",
            "epoch:65, train acc:0.78, test acc:0.6236\n",
            "epoch:66, train acc:0.7733333333333333, test acc:0.628\n",
            "epoch:67, train acc:0.79, test acc:0.633\n",
            "epoch:68, train acc:0.7933333333333333, test acc:0.6367\n",
            "epoch:69, train acc:0.7933333333333333, test acc:0.6398\n",
            "epoch:70, train acc:0.8033333333333333, test acc:0.6423\n",
            "epoch:71, train acc:0.79, test acc:0.6384\n",
            "epoch:72, train acc:0.7933333333333333, test acc:0.6434\n",
            "epoch:73, train acc:0.8, test acc:0.6485\n",
            "epoch:74, train acc:0.8133333333333334, test acc:0.6501\n",
            "epoch:75, train acc:0.8, test acc:0.656\n",
            "epoch:76, train acc:0.8166666666666667, test acc:0.6591\n",
            "epoch:77, train acc:0.8133333333333334, test acc:0.6595\n",
            "epoch:78, train acc:0.8133333333333334, test acc:0.6568\n",
            "epoch:79, train acc:0.8166666666666667, test acc:0.6601\n",
            "epoch:80, train acc:0.8166666666666667, test acc:0.6608\n",
            "epoch:81, train acc:0.82, test acc:0.6642\n",
            "epoch:82, train acc:0.82, test acc:0.6605\n",
            "epoch:83, train acc:0.8133333333333334, test acc:0.6511\n",
            "epoch:84, train acc:0.8166666666666667, test acc:0.6563\n",
            "epoch:85, train acc:0.8266666666666667, test acc:0.6625\n",
            "epoch:86, train acc:0.8333333333333334, test acc:0.6699\n",
            "epoch:87, train acc:0.8133333333333334, test acc:0.6687\n",
            "epoch:88, train acc:0.8133333333333334, test acc:0.667\n",
            "epoch:89, train acc:0.81, test acc:0.6642\n",
            "epoch:90, train acc:0.8233333333333334, test acc:0.6762\n",
            "epoch:91, train acc:0.8166666666666667, test acc:0.6694\n",
            "epoch:92, train acc:0.83, test acc:0.6802\n",
            "epoch:93, train acc:0.8233333333333334, test acc:0.6778\n",
            "epoch:94, train acc:0.8333333333333334, test acc:0.6878\n",
            "epoch:95, train acc:0.8433333333333334, test acc:0.6856\n",
            "epoch:96, train acc:0.84, test acc:0.6903\n",
            "epoch:97, train acc:0.85, test acc:0.6917\n",
            "epoch:98, train acc:0.8433333333333334, test acc:0.6907\n",
            "epoch:99, train acc:0.8333333333333334, test acc:0.6909\n",
            "epoch:100, train acc:0.84, test acc:0.6991\n",
            "epoch:101, train acc:0.85, test acc:0.6978\n",
            "epoch:102, train acc:0.8366666666666667, test acc:0.6859\n",
            "epoch:103, train acc:0.8466666666666667, test acc:0.6939\n",
            "epoch:104, train acc:0.8433333333333334, test acc:0.6876\n",
            "epoch:105, train acc:0.8533333333333334, test acc:0.6991\n",
            "epoch:106, train acc:0.8433333333333334, test acc:0.6924\n",
            "epoch:107, train acc:0.8433333333333334, test acc:0.7005\n",
            "epoch:108, train acc:0.8433333333333334, test acc:0.6978\n",
            "epoch:109, train acc:0.8433333333333334, test acc:0.6951\n",
            "epoch:110, train acc:0.8433333333333334, test acc:0.6971\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "print(os.getcwd())  # 현재 작업 디렉토리 출력\n",
        "\n",
        "# 현재 경로를 올바르게 설정 (절대 경로 사용)\n",
        "current_dir = os.path.dirname(os.path.abspath(\"C:\\\\projects\\\\jupyterProjects\\\\DeepLearning-MS-AI\\\\DL3_20241006\\\\common\"))\n",
        "print(current_dir)  # 경로 출력\n",
        "os.chdir(current_dir)  # 경로 이동\n",
        "\n",
        "# sys.path에 common 경로 추가 (import를 위해 필수)\n",
        "sys.path.append(current_dir)\n",
        "\n",
        "# 나머지 코드\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.optimizer import SGD\n",
        "from common.multi_layer_net import MultiLayerNet  # 대소문자가 다른지 확인 필요\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "# weight decay(가중치 감쇠) 설정 ===================\n",
        "weight_decay_lambda = 0.1\n",
        "\n",
        "# 신경망 설정\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10,\n",
        "                        weight_decay_lambda=weight_decay_lambda)  # 가중치 감쇠 사용\n",
        "optimizer = SGD(lr=0.01)  # 학습률 0.01의 SGD\n",
        "\n",
        "# 학습 설정\n",
        "max_epochs = 201\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "epoch_cnt = 0\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 학습 시작\n",
        "for i in range(1000000000):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산 및 매개변수 갱신\n",
        "    grads = network.gradient(x_batch, t_batch)\n",
        "    optimizer.update(network.params, grads)\n",
        "\n",
        "    # 1 에포크 당 정확도 계산 및 출력\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
        "\n",
        "        epoch_cnt += 1\n",
        "        if epoch_cnt >= max_epochs:\n",
        "            break\n",
        "\n",
        "# 그래프 그리기 ==================\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
