{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1729754153728
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\ch05\n",
            "C:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\n",
            "C:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\n",
            "===========iteration:0===========\n",
            "std=0.01:2.3024705392337474\n",
            "Xavier:2.2984238926325427\n",
            "He:2.3570266670747007\n",
            "===========iteration:100===========\n",
            "std=0.01:2.302787388048994\n",
            "Xavier:2.2648232325918567\n",
            "He:1.3941957243355905\n",
            "===========iteration:200===========\n",
            "std=0.01:2.3028207900878295\n",
            "Xavier:2.144362559850672\n",
            "He:0.8070063134160375\n",
            "===========iteration:300===========\n",
            "std=0.01:2.3016235226091437\n",
            "Xavier:1.9155059131494037\n",
            "He:0.5475144010246485\n",
            "===========iteration:400===========\n",
            "std=0.01:2.3015992028639074\n",
            "Xavier:1.4403377328739777\n",
            "He:0.4648518399527482\n",
            "===========iteration:500===========\n",
            "std=0.01:2.2995531272321514\n",
            "Xavier:0.9861169045965513\n",
            "He:0.4601552659630087\n",
            "===========iteration:600===========\n",
            "std=0.01:2.302827225616659\n",
            "Xavier:0.909424678556545\n",
            "He:0.4975027428187304\n",
            "===========iteration:700===========\n",
            "std=0.01:2.3012489759182664\n",
            "Xavier:0.7789296102262904\n",
            "He:0.48841035601623295\n",
            "===========iteration:800===========\n",
            "std=0.01:2.3012347082406066\n",
            "Xavier:0.5178357197131769\n",
            "He:0.22333288300374532\n",
            "===========iteration:900===========\n",
            "std=0.01:2.298554797166384\n",
            "Xavier:0.4601229740678216\n",
            "He:0.2664550495182849\n",
            "===========iteration:1000===========\n",
            "std=0.01:2.304556982930748\n",
            "Xavier:0.3901066020439889\n",
            "He:0.2442372991632395\n",
            "===========iteration:1100===========\n",
            "std=0.01:2.301153487597796\n",
            "Xavier:0.6429886738036208\n",
            "He:0.41054686577793253\n",
            "===========iteration:1200===========\n",
            "std=0.01:2.304471659840968\n",
            "Xavier:0.43204370306838247\n",
            "He:0.31322151216222766\n",
            "===========iteration:1300===========\n",
            "std=0.01:2.301093972243146\n",
            "Xavier:0.5313134419903593\n",
            "He:0.30633426925132934\n",
            "===========iteration:1400===========\n",
            "std=0.01:2.3016574923363122\n",
            "Xavier:0.41641268671968695\n",
            "He:0.25616752546452265\n",
            "===========iteration:1500===========\n",
            "std=0.01:2.303249263170137\n",
            "Xavier:0.3174006487197523\n",
            "He:0.14168418144450584\n",
            "===========iteration:1600===========\n",
            "std=0.01:2.297818565645057\n",
            "Xavier:0.36671018205354816\n",
            "He:0.23358132304747548\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     grads \u001b[38;5;241m=\u001b[39m networks[key]\u001b[38;5;241m.\u001b[39mgradient(x_batch, t_batch)\n\u001b[0;32m     49\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mupdate(networks[key]\u001b[38;5;241m.\u001b[39mparams, grads)\n\u001b[1;32m---> 51\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mnetworks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 배치 데이터를 통해 손실값 계산\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     train_loss[key]\u001b[38;5;241m.\u001b[39mappend(loss)  \u001b[38;5;66;03m# 계산된 손실값을 저장\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 100회마다 학습 경과 출력\u001b[39;00m\n",
            "File \u001b[1;32mC:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\multi_layer_net.py:87\u001b[0m, in \u001b[0;36mMultiLayerNet.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"손실 함수를 구한다.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    손실 함수의 값\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
            "File \u001b[1;32mC:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\multi_layer_net.py:71\u001b[0m, in \u001b[0;36mMultiLayerNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m---> 71\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mC:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\layers.py:57\u001b[0m, in \u001b[0;36mAffine.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 57\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "print(os.getcwd())  # 현재 작업 디렉토리 출력\n",
        "current_dir = r'C:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common'\n",
        "print(current_dir)  # 디렉토리 경로 출력\n",
        "os.chdir(current_dir)  # 현재 디렉토리로 변경\n",
        "# 현재 경로 출력 (디버깅용)\n",
        "print(os.getcwd())\n",
        "sys.path.append(r'C:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006')\n",
        "\n",
        "\n",
        "\n",
        "# 필요한 라이브러리 및 모듈 import\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist  # 숫자 데이터를 다운로드\n",
        "from common.util import smooth_curve\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.optimizer import SGD  # Stochastic Gradient Descent Optimizer 사용\n",
        "\n",
        "\n",
        "# 0. MNIST 데이터 읽기 ==================\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)  # MNIST 데이터셋 로드\n",
        "train_size = x_train.shape[0]  # 학습 데이터 크기 정의\n",
        "batch_size = 128  # 미니배치 크기 설정\n",
        "max_iterations = 2000  # 최대 반복 횟수 설정\n",
        "\n",
        "# 1. 실험 설정 ===================\n",
        "weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'}  # Weight 초기값 종류별 지정\n",
        "optimizer = SGD(lr=0.01)  # 학습률이 0.01인 SGD Optimizer 사용\n",
        "\n",
        "networks = {}  # 신경망 딕셔너리 생성\n",
        "train_loss = {}  # 학습 손실값을 저장할 딕셔너리 생성\n",
        "\n",
        "for key, weight_type in weight_init_types.items():  # Weight 초기화 방법별로 신경망 생성\n",
        "    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
        "                                  output_size=10, weight_init_std=weight_type)\n",
        "\n",
        "    train_loss[key] = []  # 초기 손실값 저장을 위한 리스트 생성\n",
        "\n",
        "# 2. 훈련 시작 ===================\n",
        "for i in range(max_iterations):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)  # 랜덤으로 배치 크기만큼 데이터 샘플 추출\n",
        "    x_batch = x_train[batch_mask]  # 학습용 배치 데이터\n",
        "    t_batch = t_train[batch_mask]  # 학습용 배치 레이블\n",
        "\n",
        "    for key in weight_init_types.keys():  # 네트워크별로 기울기를 계산하고 가중치를 업데이트\n",
        "        grads = networks[key].gradient(x_batch, t_batch)\n",
        "        optimizer.update(networks[key].params, grads)\n",
        "\n",
        "        loss = networks[key].loss(x_batch, t_batch)  # 배치 데이터를 통해 손실값 계산\n",
        "        train_loss[key].append(loss)  # 계산된 손실값을 저장\n",
        "\n",
        "    if i % 100 == 0:  # 100회마다 학습 경과 출력\n",
        "        print(\"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
        "        for key in weight_init_types.keys():  # Weight 초기화 방법별 손실값 출력\n",
        "            loss = networks[key].loss(x_batch, t_batch)\n",
        "            print(key + ':' + str(loss))\n",
        "\n",
        "# 3. 그래프 그리기 =================\n",
        "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}  # 그래프에 사용할 마커 지정\n",
        "x = np.arange(max_iterations)  # x축에 사용할 값들 (반복 횟수)\n",
        "\n",
        "for key in weight_init_types.keys():\n",
        "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)  # 손실값 그래프\n",
        "\n",
        "plt.xlabel(\"iterations\")  # x축 레이블\n",
        "plt.ylabel(\"loss\")  # y축 레이블\n",
        "plt.ylim(0, 2.5)  # y축 범위 설정\n",
        "plt.legend()  # 범례 표시\n",
        "plt.show()  # 그래프 출력\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
