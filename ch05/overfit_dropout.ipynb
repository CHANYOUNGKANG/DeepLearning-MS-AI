{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1729755704183
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\ch05\n",
            "train loss:2.308031819201466\n",
            "=== epoch:1, train acc:0.10333333333333333, test acc:0.0849 ===\n",
            "train loss:2.3020037329632346\n",
            "train loss:2.295998305359361\n",
            "train loss:2.3034190269762886\n",
            "=== epoch:2, train acc:0.10333333333333333, test acc:0.0807 ===\n",
            "train loss:2.3031328633123476\n",
            "train loss:2.302185644584748\n",
            "train loss:2.3008105379788444\n",
            "=== epoch:3, train acc:0.1, test acc:0.079 ===\n",
            "train loss:2.2979234172906184\n",
            "train loss:2.3003588354024234\n",
            "train loss:2.29469615309134\n",
            "=== epoch:4, train acc:0.09666666666666666, test acc:0.0822 ===\n",
            "train loss:2.3017249355358023\n",
            "train loss:2.2993632398850035\n",
            "train loss:2.304395164727212\n",
            "=== epoch:5, train acc:0.09666666666666666, test acc:0.0826 ===\n",
            "train loss:2.293053252167203\n",
            "train loss:2.296637916876661\n",
            "train loss:2.2969315453838113\n",
            "=== epoch:6, train acc:0.11, test acc:0.0832 ===\n",
            "train loss:2.2993943485442565\n",
            "train loss:2.302717740968206\n",
            "train loss:2.299102973237575\n",
            "=== epoch:7, train acc:0.11333333333333333, test acc:0.0843 ===\n",
            "train loss:2.2944935495238226\n",
            "train loss:2.3114832857105374\n",
            "train loss:2.2991823132641835\n",
            "=== epoch:8, train acc:0.12, test acc:0.087 ===\n",
            "train loss:2.297061573684498\n",
            "train loss:2.297340977118921\n",
            "train loss:2.290590590670831\n",
            "=== epoch:9, train acc:0.13333333333333333, test acc:0.0899 ===\n",
            "train loss:2.295024792073343\n",
            "train loss:2.293550913336239\n",
            "train loss:2.2945044492419426\n",
            "=== epoch:10, train acc:0.13, test acc:0.0917 ===\n",
            "train loss:2.298932108216697\n",
            "train loss:2.2947978833317366\n",
            "train loss:2.2911534252523125\n",
            "=== epoch:11, train acc:0.12666666666666668, test acc:0.0944 ===\n",
            "train loss:2.297409608706701\n",
            "train loss:2.293924977367972\n",
            "train loss:2.304512142767546\n",
            "=== epoch:12, train acc:0.13, test acc:0.0974 ===\n",
            "train loss:2.295360308313299\n",
            "train loss:2.2892901715620755\n",
            "train loss:2.2966397366101474\n",
            "=== epoch:13, train acc:0.14, test acc:0.1002 ===\n",
            "train loss:2.292524072256798\n",
            "train loss:2.2952908041495665\n",
            "train loss:2.2908330221976136\n",
            "=== epoch:14, train acc:0.13666666666666666, test acc:0.1017 ===\n",
            "train loss:2.2896761302105904\n",
            "train loss:2.288328623683731\n",
            "train loss:2.2875104357814933\n",
            "=== epoch:15, train acc:0.13, test acc:0.1037 ===\n",
            "train loss:2.29401822603697\n",
            "train loss:2.300279133817861\n",
            "train loss:2.3064126893132957\n",
            "=== epoch:16, train acc:0.12333333333333334, test acc:0.1052 ===\n",
            "train loss:2.285560326441878\n",
            "train loss:2.293318495038646\n",
            "train loss:2.293307142609526\n",
            "=== epoch:17, train acc:0.11666666666666667, test acc:0.1056 ===\n",
            "train loss:2.285563164310428\n",
            "train loss:2.2860332379162487\n",
            "train loss:2.2899655407171613\n",
            "=== epoch:18, train acc:0.11, test acc:0.1055 ===\n",
            "train loss:2.290925023084424\n",
            "train loss:2.28681277816692\n",
            "train loss:2.290408392497514\n",
            "=== epoch:19, train acc:0.10666666666666667, test acc:0.1076 ===\n",
            "train loss:2.2958680890583234\n",
            "train loss:2.293887330060627\n",
            "train loss:2.2867231621504716\n",
            "=== epoch:20, train acc:0.11333333333333333, test acc:0.1118 ===\n",
            "train loss:2.288583518253664\n",
            "train loss:2.2963186748979347\n",
            "train loss:2.291627987735977\n",
            "=== epoch:21, train acc:0.11333333333333333, test acc:0.1143 ===\n",
            "train loss:2.2892638426620637\n",
            "train loss:2.2895006248182606\n",
            "train loss:2.2923945270119783\n",
            "=== epoch:22, train acc:0.11666666666666667, test acc:0.1162 ===\n",
            "train loss:2.290227300978729\n",
            "train loss:2.284214705562142\n",
            "train loss:2.2881827324584214\n",
            "=== epoch:23, train acc:0.12333333333333334, test acc:0.1211 ===\n",
            "train loss:2.2939186457842395\n",
            "train loss:2.285505508808927\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 학습을 담당할 Trainer 생성\u001b[39;00m\n\u001b[0;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(network, x_train, t_train, x_test, t_test, \n\u001b[0;32m     37\u001b[0m                   epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m301\u001b[39m, mini_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# 301 에포크 동안 미니배치 크기 100으로 학습\u001b[39;00m\n\u001b[0;32m     38\u001b[0m                   optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer_param\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m}, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# SGD Optimizer 사용, 학습률 0.01\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 학습 시작\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 학습된 결과를 저장\u001b[39;00m\n\u001b[0;32m     43\u001b[0m train_acc_list, test_acc_list \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_acc_list, trainer\u001b[38;5;241m.\u001b[39mtest_acc_list  \u001b[38;5;66;03m# 학습 정확도와 테스트 정확도 리스트\u001b[39;00m\n",
            "File \u001b[1;32mc:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\trainer.py:71\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[1;32m---> 71\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39maccuracy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_test)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
            "File \u001b[1;32mc:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\trainer.py:47\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mgradient(x_batch, t_batch)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparams, grads)\n\u001b[1;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(loss))\n",
            "File \u001b[1;32mc:\\projects\\jupyterProjects\\DeepLearning-MS-AI\\DL3_20241006\\common\\multi_layer_net_extend.py:104\u001b[0m, in \u001b[0;36mMultiLayerNetExtend.loss\u001b[1;34m(self, x, t, train_flg)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    103\u001b[0m     W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx)]\n\u001b[1;32m--> 104\u001b[0m     weight_decay \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_decay_lambda \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_layer\u001b[38;5;241m.\u001b[39mforward(y, t) \u001b[38;5;241m+\u001b[39m weight_decay\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:2344\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2338\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `min` or `max` keyword argument when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2339\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2345\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m   2349\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2351\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "##############################\n",
        "import os, sys\n",
        "print(os.getcwd())  # 현재 작업 디렉토리 출력\n",
        "\n",
        "# __file__ 대신 os.getcwd()를 사용해 현재 작업 디렉토리로 경로 설정\n",
        "# 주피터 노트북에서는 __file__ 대신 os.getcwd()를 사용\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)  # dataset 폴더의 상위 경로를 sys.path에 추가\n",
        "sys.path.append(os.path.join(os.getcwd(), '..', 'common'))  # common 폴더 경로를 추가\n",
        "##############################\n",
        "# Import 부분이 올바른지 확인\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend  # 확장된 다층 신경망\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist  # MNIST 데이터셋 로드\n",
        "from common.trainer import Trainer  # 학습을 관리할 Trainer 클래스\n",
        "\n",
        "# MNIST 데이터셋 불러오기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 오버피팅을 방지하기 위해 학습 데이터 일부만 사용\n",
        "x_train = x_train[:300]  # 훈련 데이터의 첫 300개만 사용\n",
        "t_train = t_train[:300]  # 레이블 데이터의 첫 300개만 사용\n",
        "\n",
        "# 드롭아웃 사용 여부와 비율 설정\n",
        "use_dropout = True  # 드롭아웃을 사용할 경우 True, 사용하지 않을 경우 False\n",
        "dropout_ratio = 0.2  # 드롭아웃 비율을 20%로 설정\n",
        "\n",
        "# 신경망 생성: Dropout 옵션 설정\n",
        "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], \n",
        "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)  # 'dropout_ratio'를 'dropout_ration'으로 변경\n",
        "\n",
        "# 학습을 담당할 Trainer 생성\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test, \n",
        "                  epochs=301, mini_batch_size=100,  # 301 에포크 동안 미니배치 크기 100으로 학습\n",
        "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)  # SGD Optimizer 사용, 학습률 0.01\n",
        "\n",
        "trainer.train()  # 학습 시작\n",
        "\n",
        "# 학습된 결과를 저장\n",
        "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list  # 학습 정확도와 테스트 정확도 리스트\n",
        "\n",
        "# 그래프 그리기 =================\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))  # 에포크 수만큼의 x축 데이터 생성\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)  # 학습 데이터의 정확도를 그래프로 표시\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)  # 테스트 데이터의 정확도를 그래프로 표시\n",
        "plt.xlabel(\"epochs\")  # x축 레이블\n",
        "plt.ylabel(\"accuracy\")  # y축 레이블\n",
        "plt.ylim(0, 1.0)  # y축 범위 설정\n",
        "plt.legend(loc='lower right')  # 범례 설정\n",
        "plt.show()  # 그래프 출력\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
